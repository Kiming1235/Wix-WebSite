# Robots.txt - SEO Configuration

# 기본 규칙
User-agent: *
Allow: /
Allow: /sitemap.xml
Disallow: /admin/
Disallow: /private/
Disallow: /api/
Disallow: /*?lightbox=
Disallow: /*?*sort=
Disallow: /*?*filter=
Disallow: /*.json$
Disallow: /*.xml$   # 다른 XML 크롤링 제한
# Google은 Crawl-delay/Request-rate를 무시하므로 전역에서 사용 안 함

# Google
User-agent: Googlebot
Allow: /

# Bing
User-agent: Bingbot
Allow: /
Crawl-delay: 1

# Yandex
User-agent: YandexBot
Allow: /
Crawl-delay: 1

# Baidu
User-agent: Baiduspider
Allow: /
Crawl-delay: 1

# Naver (국내)
User-agent: Yeti
Allow: /

# 악성/과도한 봇 제한
User-agent: AhrefsBot
User-agent: SemrushBot
User-agent: DotBot
Disallow: /
Crawl-delay: 10

# Sitemap 절대경로(정식 도메인)
Sitemap: https://www.daehancargocrane.com/sitemap.xml
