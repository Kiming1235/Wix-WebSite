# Robots.txt for 대한카고크레인
# Allow all search engines to crawl the site

User-agent: *
Allow: /
Disallow: /admin
Disallow: /private
Disallow: /*.json$
Disallow: /*.xml$

# Specific rules for major search engines
User-agent: Googlebot
Allow: /
Crawl-delay: 0

User-agent: Bingbot
Allow: /
Crawl-delay: 1

User-agent: Yeti
Allow: /
Crawl-delay: 0

User-agent: NaverBot
Allow: /
Crawl-delay: 0

# Sitemap location
Sitemap: https://www.daehancargocranes.com/sitemap.xml
