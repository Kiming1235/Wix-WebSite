# Robots.txt - SEO Configuration

# 기본 규칙
User-agent: *
Allow: /
Allow: /sitemap.xml$
Allow: /gyeongsan
Allow: /daegu
Allow: /gyeongju
Allow: /cheongdo
Allow: /gunwi
Allow: /yeongcheon

Disallow: /admin/
Disallow: /private/
Disallow: /api/
Disallow: /*?lightbox=
Disallow: /*?*sort=
Disallow: /*?*filter=
Disallow: /*.json$
Disallow: /*.xml$   # 다른 XML 크롤링 제한 (단, sitemap.xml은 예외)

# Google
User-agent: Googlebot
Allow: /

# Bing
User-agent: Bingbot
Allow: /
Crawl-delay: 1

# Yandex
User-agent: YandexBot
Allow: /
Crawl-delay: 1

# Baidu
User-agent: Baiduspider
Allow: /
Crawl-delay: 1

# Naver (국내)
User-agent: Yeti
Allow: /

# 악성/과도한 봇 제한
User-agent: AhrefsBot
User-agent: SemrushBot
User-agent: DotBot
Disallow: /
Crawl-delay: 10

# Sitemap 절대경로(정식 도메인)
Sitemap: https://www.daehancargocrane.com/sitemap.xml
